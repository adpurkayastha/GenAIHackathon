{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8a39a5b",
   "metadata": {},
   "source": [
    "# Codesphere - Hackathon working notebook\n",
    "\n",
    "This notebook will serve as a working prototype for our hackathon problem statement. \n",
    "\n",
    "**Problem Statement:** Notes Summarizer for an Invoice collections application. \n",
    "\n",
    "**Description:** Our aim is to create an AI generated summary of all the notes added against a given client. The summary will save time for the collections agent as he/she will not be required to peruse all the notes available in the system for a given client to get the gist of the client standing and past history. The summary should be able to identify the key points from past notes, summarize them in a cohesive and readable manner and display them in not more than 2 paragraphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecf14c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers\n",
    "# pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7fc8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade --user transformers sentencepiece protobuf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2251236b",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "179f72f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration,BartTokenizer, BartForConditionalGeneration\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee381dcf",
   "metadata": {},
   "source": [
    "We will initialize the tokenizer with a base model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e73f32d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adpur\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:246: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on google-t5/t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('google-t5/t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('google-t5/t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efecb35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BART Model\n",
    "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118fe303",
   "metadata": {},
   "source": [
    "For phase 1, we will main note related data in an input file and load it. The file has the below columns\n",
    "\n",
    "* Client name - This will be our primary reference.\n",
    "* Note Date - When this particular note was added. \n",
    "* Note Comment - The actual comment data that needs to be summarized. \n",
    "\n",
    "Note that the file can have multiple notes for the same client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54eb0257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file\n",
    "df = pd.read_excel('Dataset.xlsx', engine='openpyxl')\n",
    "df.columns = ['Invoice Number','Client Name', 'Note Date', 'Note Comment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1c019d",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We shall not enter in-depth into data preprocessing for phase 1, but what we will do is to add a date reference to the note input by concatenating the note date with the comment. \n",
    "\n",
    "In order to make it more human readable, we will add some formatting. Hence, 01-Jan-2024 will read as 1st Jan and 15-Jan-2024 will read as 15th Jan. As there is no in-built function to add the ordinal indicator we want using [grammarly](https://www.grammarly.com/blog/how-to-write-ordinal-numbers-correctly/) as a reference :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "604ee3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ordinal_indicator(date):\n",
    "    day = date.day\n",
    "    if 4 <= day <= 20 or 24 <= day <= 30:\n",
    "        suffix = \"th\"\n",
    "    else:\n",
    "        suffix = [\"st\", \"nd\", \"rd\"][day % 10 - 1]\n",
    "    return f\"Update On: {day}{suffix} {date.strftime('%b %Y')}, \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35ac78",
   "metadata": {},
   "source": [
    "Now to concatenate the notes itself... We will create a data dictionary to hold the output for every client. Finally we will pass the output to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c361968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## some pre-processing\n",
    "Client_Notes = {}\n",
    "\n",
    "df = df.sort_values(by=['Client Name', 'Note Date'], ascending=[True, True])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    Client = row['Client Name']\n",
    "    #Invoice = row['Invoice Number']\n",
    "    \n",
    "    # If this is the first note for this client, create a new list for them\n",
    "    if Client not in Client_Notes:\n",
    "        Client_Notes[Client] = ''\n",
    "    \n",
    "    #Siddesh - Added this check as empty note was giving summarizing issues. \n",
    "    if row['Note Comment'] is not None:\n",
    "        # Format the date and prepend it to the note\n",
    "        note_date = add_ordinal_indicator(row['Note Date'])\n",
    "        note_with_date = note_date + row['Note Comment'].strip()\n",
    "        \n",
    "        if note_with_date[-1] !='.':\n",
    "            note_with_date = note_with_date + '.'\n",
    "        if note_with_date[0] =='.':\n",
    "            note_with_date = note_with_date[1:]\n",
    "        \n",
    "        Client_Notes[Client] += note_with_date\n",
    "\n",
    "#summary_df = pd.DataFrame(columns=['Invoice Number','Client Name', 'Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb0604",
   "metadata": {},
   "source": [
    "# Generating the summary\n",
    "\n",
    "We will now ask the model to generate summarized text for each client with a 205 char limit. We prefix the concatenated notes with a prompt \"Summary:\" to let the model know that we are expecting summarized output. This gets saved to a new dataframe.\n",
    "We are also comparing two LLM models:\n",
    "\n",
    "1. T5 from Google\n",
    "2. BART from Facebook\n",
    "\n",
    "We will compare outputs from both these models to see which one performs better against the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4cef626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can generate the summary for each client and add it to the DataFrame. \n",
    "summaries = []\n",
    "for client, notes in Client_Notes.items():\n",
    "   \n",
    "    # Generate summary using T5\n",
    "    inputs = tokenizer.encode(\"summarize: \" + notes, return_tensors='pt', max_length=1024, truncation=True)\n",
    "    outputs = model.generate(\n",
    "    inputs, \n",
    "    max_length=250, \n",
    "    min_length=40, \n",
    "    length_penalty=2, \n",
    "    num_beams=6,\n",
    "    #do_sample=True ,    \n",
    "    #temperature=0.7,  # Controls randomness, lower is more deterministic\n",
    "    #top_k=50,          # Considers only the top k words by probability\n",
    "    #top_p=0.6         # Nucleus sampling: keeps the top p probability mass\n",
    "    )\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Generate summary using BART\n",
    "    bart_inputs = bart_tokenizer(notes, return_tensors='pt', max_length=1024, truncation=True, padding='max_length')\n",
    "    bart_outputs = bart_model.generate(\n",
    "    bart_inputs['input_ids'], \n",
    "    max_length=250, \n",
    "    min_length=40, \n",
    "    length_penalty=2, \n",
    "    num_beams=6,\n",
    "    #do_sample=True,    \n",
    "    #temperature=0.7,   # Consistency in parameters for fair comparison\n",
    "    #top_k=50,\n",
    "    #top_p=0.6\n",
    "    )\n",
    "    bart_summary = bart_tokenizer.decode(bart_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    summaries.append({'Client Name': client, 'T5 Summary': summary,'BART Summary': bart_summary})\n",
    "    \n",
    "# Create DataFrame after loop\n",
    "summary_df = pd.DataFrame(summaries)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0279cb",
   "metadata": {},
   "source": [
    "# Saving the output to file\n",
    "\n",
    "For phase 1 - We will save the output back to our dataset file under summary tab. Note that we will overwrite any old output as each run is considered fresh. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daaa0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('Dataset.xlsx', engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    summary_df.to_excel(writer, sheet_name='Summary', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c09409",
   "metadata": {},
   "source": [
    "# Summary analysis\n",
    "\n",
    "Let us have a peek into the summary generated by the model and see how the output compares to the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ef07095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:\n",
      "Update On: 1st Jan 2024, Reached out to client AP contact for payment of 10 open invoices totaling 10250 USD.Update On: 15th Jan 2024, Client advised that there is cash crunch impacting fund transfer. Partial payment expected by Jan Month end with further settlements in Feb.Update On: 2nd Feb 2024, As discussed, partial payment of 5,000 USD received via wire transfer.Update On: 14th Feb 2024, Had further follow-up with client on remaining open balance. This includes newly created 5 invoices with a value of 4000 USD leading to open balance of 12250 USD.Update On: 1st Mar 2024, Client has released another partial payment of 8000 USD. Had discussion with AP contact on settlement plan for current open balance.Update On: 15th Mar 2024, AP Contact has been changed from John to Matthew effective immediately. Matthew will be the SPOC for all payments going forward.Update On: 1st Apr 2024, Client has released full payment for all open invoices, effectively closing out the dunning process for current open AR. Expect all payments to be applied by 5th April in the system.\n",
      "\n",
      "\n",
      "Output T5 summary:\n",
      "there is cash crunch impacting fund transfer. partial payment expected by Jan Month end with further settlements in Feb. Client has released full payment for all open invoices. expect all payments to be applied by 5th April in the system.\n",
      "\n",
      "\n",
      "Output BART summary:\n",
      "Update On: 15th Mar 2024, AP Contact has been changed from John to Matthew effective immediately. Matthew will be the SPOC for all payments going forward. Expect all payments to be applied by 5th April in the system.\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Text:\")\n",
    "print(Client_Notes['A'])\n",
    "print(\"\\n\")\n",
    "print(\"Output T5 summary:\")\n",
    "print(summary_df['T5 Summary'][0])\n",
    "print(\"\\n\")\n",
    "print(\"Output BART summary:\")\n",
    "print(summary_df['BART Summary'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7a464de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:\n",
      "Update On: 13th Jan 2024, Sent initial chaser to client on outstanding balance.Update On: 1st Feb 2024, Per email from Jim (AP), B LLC has expressed an inability to pay at the moment and promised to make a payment by 1st March. EP has been looped in to advise further.Update On: 14th Feb 2024, Per EP advise, we will pause follow-ups till PTP expires.Update On: 27th Feb 2024, As per latest update from Jim, B LLC is under financial strain and might not be able to make payment on agreed upon date. They are unable to commit to a new date, but instead have mentioned payment in \"near future\".Update On: 13th Mar 2024, Had discussion with EP on this during weekly call. The client will be sent to bad debt collection.Update On: 17th Mar 2024, Invoices sent to Bad debt collection. Payment is not expected and might need a write-off.\n",
      "\n",
      "\n",
      "Output T5 summary:\n",
      "B LLC has expressed an inability to pay at the moment and promised to make a payment by 1st march. unable to commit to a new date, but instead have mentioned payment in \"near future\" the client will be sent to bad debt collection; payment is not expected and might need a write-off.\n",
      "\n",
      "\n",
      "Output BART summary:\n",
      "Update On: 13th Jan 2024, Sent initial chaser to client on outstanding balance. Per email from Jim (AP), B LLC has expressed an inability to pay at the moment and promised to make a payment by 1st March.\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Text:\")\n",
    "print(Client_Notes['B'])\n",
    "print(\"\\n\")\n",
    "print(\"Output T5 summary:\")\n",
    "print(summary_df['T5 Summary'][1])\n",
    "print(\"\\n\")\n",
    "print(\"Output BART summary:\")\n",
    "print(summary_df['BART Summary'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e05dbee",
   "metadata": {},
   "source": [
    "As we can see, the summary in question is extractive in nature - Meaning that the model has actually used the input data passed and picked key points and stitched them together to generate a summary.\n",
    "\n",
    "Now, this is a start, but we eventually want it to generate abstract summary so that it can add new words to form a more cohesive summary. \n",
    "\n",
    "Neither model does a 100% perfect job and both show that they can be better than the other,depending upon the input.\n",
    "\n",
    "So, we need more training data to fine tune the models to generate abstractive summarization and then compare the performance and pick the best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2bf0e6",
   "metadata": {},
   "source": [
    "# Lets try generating the summaries with a fine tuned T5 model\n",
    "\n",
    "For now we we used the BBC News dataset from Hugging Face for fine tuning our T5 Model.This dataset for extractive text summarization has four hundred and seventeen political news articles of BBC from 2004 to 2005 in the News Articles folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fc9f519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR = 'results_t5base'\n",
    "model_path = f\"{OUT_DIR}/checkpoint-1110\"  # the path where we saved our fine tuned model\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = T5Tokenizer.from_pretrained(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0704434",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_tuned = []\n",
    "for client, notes in Client_Notes.items():\n",
    "   \n",
    "    # Generate summary using T5\n",
    "    inputs = tokenizer.encode(\"summarize: \" + notes, return_tensors='pt', max_length=1024, truncation=True)\n",
    "    outputs = model.generate(\n",
    "    inputs, \n",
    "    max_length=250\n",
    "    )\n",
    "    summary_tuned = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    summaries_tuned.append({'Client Name': client, 'T5 Summary': summary_tuned})\n",
    "    \n",
    "# Create DataFrame after loop\n",
    "summary_tuned_df = pd.DataFrame(summaries_tuned)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cc7f039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:\n",
      "Update On: 1st Jan 2024, Reached out to client AP contact for payment of 10 open invoices totaling 10250 USD.Update On: 15th Jan 2024, Client advised that there is cash crunch impacting fund transfer. Partial payment expected by Jan Month end with further settlements in Feb.Update On: 2nd Feb 2024, As discussed, partial payment of 5,000 USD received via wire transfer.Update On: 14th Feb 2024, Had further follow-up with client on remaining open balance. This includes newly created 5 invoices with a value of 4000 USD leading to open balance of 12250 USD.Update On: 1st Mar 2024, Client has released another partial payment of 8000 USD. Had discussion with AP contact on settlement plan for current open balance.Update On: 15th Mar 2024, AP Contact has been changed from John to Matthew effective immediately. Matthew will be the SPOC for all payments going forward.Update On: 1st Apr 2024, Client has released full payment for all open invoices, effectively closing out the dunning process for current open AR. Expect all payments to be applied by 5th April in the system.\n",
      "\n",
      "\n",
      "Output T5 summary:\n",
      "The On: 1st Mar 2024, Client has released full payment for all open invoices, effectively closing out the dunning process for current open AR.The On: 1st Mar 2024, Client has released full payment for all open invoices, effectively closing out the dunning process for current open AR.The On: 1st Mar 2024, Client has released full payment for all open invoices, effectively closing out the dunning process for current open AR.\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Text:\")\n",
    "print(Client_Notes['A'])\n",
    "print(\"\\n\")\n",
    "print(\"Output T5 summary:\")\n",
    "print(summary_tuned_df['T5 Summary'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84146ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:\n",
      "Update On: 13th Jan 2024, Sent initial chaser to client on outstanding balance.Update On: 1st Feb 2024, Per email from Jim (AP), B LLC has expressed an inability to pay at the moment and promised to make a payment by 1st March. EP has been looped in to advise further.Update On: 14th Feb 2024, Per EP advise, we will pause follow-ups till PTP expires.Update On: 27th Feb 2024, As per latest update from Jim, B LLC is under financial strain and might not be able to make payment on agreed upon date. They are unable to commit to a new date, but instead have mentioned payment in \"near future\".Update On: 13th Mar 2024, Had discussion with EP on this during weekly call. The client will be sent to bad debt collection.Update On: 17th Mar 2024, Invoices sent to Bad debt collection. Payment is not expected and might need a write-off.\n",
      "\n",
      "\n",
      "Output T5 summary:\n",
      "The client will be sent to bad debt collection.Update on: 27th Mar 2024, As per latest update from Jim, B LLC is under financial strain and might not be able to make payment on agreed upon date.The client will be sent to bad debt collection.The client will be sent to bad debt collection.The client will be sent to bad debt collection.The client will be sent to bad debt collection.The client will be sent to bad debt collection.The client will\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Text:\")\n",
    "print(Client_Notes['B'])\n",
    "print(\"\\n\")\n",
    "print(\"Output T5 summary:\")\n",
    "print(summary_tuned_df['T5 Summary'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6acb5453",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('Dataset.xlsx', engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    summary_tuned_df.to_excel(writer, sheet_name='Summary_Tuned', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
